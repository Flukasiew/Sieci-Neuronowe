{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Introduction and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nn_utils\n",
    "%matplotlib inline\n",
    "\n",
    "print('TensorFlow Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Initializing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.L = len(layers)\n",
    "        self.num_features = layers[0]\n",
    "        self.num_classes = layers[-1]\n",
    "        \n",
    "        self.W = {}\n",
    "        self.b = {}\n",
    "        \n",
    "        self.dW = {}\n",
    "        self.db = {}\n",
    "        \n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self):\n",
    "        \n",
    "        # Initalize weights\n",
    "        for i in range(1, self.L):\n",
    "            #Xavier Initialziation\n",
    "            self.W[i] = tf.Variable(tf.random.normal(shape=(self.layers[i], self.layers[i-1])) * np.sqrt(2 / self.layers[0]))\n",
    "            #self.W[i] = tf.Variable(tf.random.normal(shape=(self.layers[i], self.layers[i-1]))) #Wx+b\n",
    "            self.b[i] = tf.Variable(tf.ones(shape=(self.layers[i],1))) #b\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        A = tf.convert_to_tensor(X, dtype=tf.float32) #Get input to work with tf\n",
    "        for i in range(1, self.L):\n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
    "            #activation\n",
    "            if i!= self.L-1:\n",
    "                A = tf.nn.relu(Z)\n",
    "            else:\n",
    "                #final layer activation, in this case nothing happens\n",
    "                A=Z\n",
    "        return A\n",
    "    \n",
    "    def compute_loss(self, A, Y):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    def update_params(self, lr):\n",
    "        for i in range(1,self.L):\n",
    "            self.W[i].assign_sub(lr*self.dW[i])\n",
    "            self.b[i].assign_sub(lr*self.db[i])\n",
    "            \n",
    "    def predict(self, X):\n",
    "        A = self.forward_pass(X)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis=1)\n",
    "    \n",
    "    def info(self):\n",
    "        num_params = 0\n",
    "        for i in range(1, self.L):\n",
    "            num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
    "            num_params += self.b[i].shape[0]\n",
    "        print('Input Features:', self.num_features)\n",
    "        print('Number of Classes:', self.num_classes)\n",
    "        print('Hidden Layers:')\n",
    "        print('--------------')\n",
    "        for i in range(1, self.L-1):\n",
    "            print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
    "        print('--------------')\n",
    "        print('Number of parameters:', num_params)\n",
    "        \n",
    "    def train_on_batch(self, X, Y, lr):\n",
    "        X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            A = self.forward_pass(X)\n",
    "            loss = self.compute_loss(A, Y)\n",
    "        \n",
    "        for i in range(1, self.L):\n",
    "            self.dW[i] = tape.gradient(loss, self.W[i])\n",
    "            self.db[i] = tape.gradient(loss, self.b[i])\n",
    "        del tape\n",
    "        self.update_params(lr)\n",
    "        return loss.numpy() \n",
    "    \n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr):\n",
    "        # Your code here\n",
    "        history = {\n",
    "            'val_loss': [], \n",
    "            'train_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            epoch_train_loss = 0\n",
    "            print(f'Epoch {e}', end='.')\n",
    "            for i in range(steps_per_epoch):\n",
    "                x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss = self.train_on_batch(x_batch, y_batch, lr)\n",
    "                epoch_train_loss += batch_loss\n",
    "                \n",
    "                if i%int(np.ceil(steps_per_epoch/10)) == 0:\n",
    "                    print(end='.')\n",
    "                    \n",
    "            history['train_loss'] = epoch_train_loss\n",
    "            val_A = self.forward_pass(x_test)\n",
    "            val_loss = self.compute_loss(val_A, y_test).numpy()\n",
    "            history['val_loss'] = val_loss\n",
    "            val_preds = self.predict(x_test)\n",
    "            val_acc = np.mean(val_preds.numpy() == np.argmax(y_test, axis=1))\n",
    "            history['val_acc'] = val_acc\n",
    "            print('val acc:', val_acc)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def forward_pass(self, X):\n",
    "        A = tf.convert_to_tensor(X, dtype=tf.float32) #Get input to work with tf\n",
    "        for i in range(1, self.L):\n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
    "            #activation\n",
    "            if i!= self.L-1:\n",
    "                A = tf.nn.relu(Z)\n",
    "            else:\n",
    "                A=Z\n",
    "        return A\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Computing Loss and Updating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def compute_loss(self, A, Y):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    def update_params(self, lr):\n",
    "        for i in range(1,self.L):\n",
    "            self.W[i].assign_sub(lr*self.dW[i])\n",
    "            self.b[i].assign_sub(lr*self.db[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Predict and Info Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def predict(self, X):\n",
    "        A = self.forward_pass(X)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis=1)\n",
    "    \n",
    "    def info(self):\n",
    "        num_params = 0\n",
    "        for i in range(1, self.L):\n",
    "            num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
    "            num_params += self.b[i].shape[0]\n",
    "        print('Input Features:', self.num_features)\n",
    "        print('Number of Classes:', self.num_classes)\n",
    "        print('Hidden Layers:')\n",
    "        print('--------------')\n",
    "        for i in range(1, self.L-1):\n",
    "            print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
    "        print('--------------')\n",
    "        print('Number of parameters:', num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Training on Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_on_batch(self, X, Y, lr):\n",
    "        X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            A = self.forward_pass(X)\n",
    "            loss = self.compute_loss(A, Y)\n",
    "        \n",
    "        for i in range(1, self.L):\n",
    "            self.dW[i] = tape.gradient(loss, self.W[i])\n",
    "            self.db[i] = tape.gradient(loss, self.b[i])\n",
    "        del tape\n",
    "        self.update_params(lr)\n",
    "        return loss.numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Training on Complete Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr):\n",
    "        # Your code here\n",
    "        history = {\n",
    "            'val_loss': [], \n",
    "            'train_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            epoch_train_loss = 0\n",
    "            print(f'Epoch {e}', end='.')\n",
    "            for i in range(steps_per_epoch):\n",
    "                x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss = self.train_on_batch(x_batch, y_batch, lr)\n",
    "                epoch_train_loss += batch_loss\n",
    "                \n",
    "                if i%int(np.ceil(steps_per_epoch/10)) == 0:\n",
    "                    print(end='.')\n",
    "                    \n",
    "            history['train_loss'] = epoch_train_loss\n",
    "            val_A = self.forward_pass(x_test)\n",
    "            val_loss = self.compute_loss(val_A, y_test).numpy()\n",
    "            history['val_loss'] = val_loss\n",
    "            val_preds = self.predict(x_test)\n",
    "            val_acc = np.mean(val_preds.numpy() == np.argmax(y_test, axis=1))\n",
    "            history['val_acc'] = val_acc\n",
    "            print('val acc:', val_acc)\n",
    "        return history\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8: Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = nn_utils.load_data()\n",
    "nn_utils.plot_random_examples(x_train, y_train).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork([784,128,128,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features: 784\n",
      "Number of Classes: 10\n",
      "Hidden Layers:\n",
      "--------------\n",
      "Layer 1, Units 128\n",
      "Layer 2, Units 128\n",
      "--------------\n",
      "Number of parameters: 118282\n"
     ]
    }
   ],
   "source": [
    "net.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "epochs = 100\n",
    "steps_per_epoch = int(np.ceil(x_train.shape[0]/ batch_size))\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 15:02:39.106866: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-01-07 15:02:39.106928: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18661/2882236975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m net.train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18661/1333202624.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18661/1333202624.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, X, Y, lr)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18661/1333202624.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Get input to work with tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/sieci/projekt3/siec/env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/sieci/projekt3/siec/env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "net.train(\n",
    "    x_train, y_train,\n",
    "    x_test, y_test,\n",
    "    epochs, steps_per_epoch, \n",
    "    batch_size, lr\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9372"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(net.predict(x_test) == np.argmax(y_test,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9: Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
